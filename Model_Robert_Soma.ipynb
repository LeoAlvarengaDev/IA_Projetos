{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/mfmarlonferrari/NietzscheLLM/blob/main/IntroLLMTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"p9E5ma6nvs2n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716721053307,"user_tz":180,"elapsed":108163,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"9de90eef-34d6-44dd-dce5-b19f28c0e003"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.7.0\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n","Collecting accelerate>=0.21.0 (from transformers[torch])\n","  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","ERROR: unknown command \"instal\" - maybe you meant \"install\"\n"]}],"source":["!pip install tiktoken\n","!pip install transformers[torch]\n","!pip install pandas\n","!pip instal numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTaCX_ah3NE9"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tiktoken\n","from transformers import RobertaConfig\n","from transformers import RobertaTokenizer\n","from transformers import RobertaForMaskedLM\n","from transformers import pipeline\n","from transformers import LineByLineTextDataset\n","from transformers import DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","from tokenizers import ByteLevelBPETokenizer\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import ByteLevel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpm4jumQ6Xor"},"outputs":[],"source":["\n","# Gerar dados de treinamento e validação\n","np.random.seed(42)\n","train_data = [(np.random.randint(0, 1000), np.random.randint(0, 1000)) for _ in range(10000)]\n","val_data = [(np.random.randint(0, 1000), np.random.randint(0, 1000)) for _ in range(2000)]\n","\n","# Preparar os dados em um DataFrame\n","\n","#df para treinar\n","train_df = pd.DataFrame(train_data, columns=['num1', 'num2'])\n","train_df['sum'] = train_df['num1'] + train_df['num2']\n","\n","\n","frase = []\n","for i in train_df.index:\n","    x = train_df.iloc[i].values\n","    frase.append(f'{x[0]} + {x[1]} = {x[2]}')"]},{"cell_type":"code","source":["len(frase)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4jRyu6Bg7hU5","executionInfo":{"status":"ok","timestamp":1716677137932,"user_tz":180,"elapsed":350,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"169d3119-24ab-4b0b-f197-b473b7573587"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10000"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-MAFzN2G0sl"},"outputs":[],"source":["# Salva os dados de treinamento em um arquivo temporário\n","with open(\"temp_dados_treino.txt\", \"w\") as f:\n","    for item in frase:\n","        f.write(f\"{item}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fn-BL7d8EhFt"},"outputs":[],"source":["# Inicializa o ByteLevelBPETokenizer\n","tokenizer = ByteLevelBPETokenizer()\n","\n","# Treina o tokenizador\n","tokenizer.train(files=[\"temp_dados_treino.txt\"], vocab_size=10_000, min_frequency=2, special_tokens=[\n","    \"<s>\",\n","    \"<pad>\",\n","    \"</s>\",\n","    \"<unk>\",\n","    \"<mask>\",\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1716721120067,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"},"user_tz":180},"id":"UuHqy1hBHBcU","outputId":"645619fe-1bf8-4822-ee7f-f8f42906a415"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['modelo_tokenizer/vocab.json', 'modelo_tokenizer/merges.txt']"]},"metadata":{},"execution_count":7}],"source":["# Salva o tokenizador treinado\n","!mkdir modelo_tokenizer\n","tokenizer.save_model(\"modelo_tokenizer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pT8-2R7YXbqP"},"outputs":[],"source":["tokenizer = RobertaTokenizer.from_pretrained('modelo_tokenizer', max_len=512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OS9PQwyiZG-M"},"outputs":[],"source":["from transformers import RobertaConfig\n","\n","config = RobertaConfig(\n","    vocab_size=10_000,\n","    max_position_embeddings=312,\n","    num_attention_heads=6,\n","    num_hidden_layers=3,\n","    type_vocab_size=1,\n",")\n","\n","from transformers import RobertaForMaskedLM\n","model = RobertaForMaskedLM(config=config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1716721152622,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"},"user_tz":180},"id":"7pRaNBr2ZLL1","outputId":"ba1c3080-de71-4595-f8ef-2f3913bb4e02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["29787664"]},"metadata":{},"execution_count":12}],"source":["model.num_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voa_zL7iZNsl"},"outputs":[],"source":["#forma simples de se carregar um arquivo bruto como Dataset\n","from transformers import LineByLineTextDataset\n","\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path='temp_dados_treino.txt',\n","    block_size=128,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1716721162806,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"},"user_tz":180},"id":"oug3pUOnZuQY","outputId":"8684e876-e38c-4ad8-aac5-7ba4ee6e0941"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'input_ids': tensor([   0, 1636,  261, 1205,  262,  678,    2])},\n"," {'input_ids': tensor([   0, 2589,  261,  762,  262, 2175,    2])}]"]},"metadata":{},"execution_count":14}],"source":["# verificando\n","dataset.examples[:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1716721165885,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"},"user_tz":180},"id":"1hhGLnDxaCBL","outputId":"57ff8176-aced-4008-c799-6048d9876a2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<s>87 + 372 = 459</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["tokenizer.decode(dataset.examples[7]['input_ids'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IK_VP-zcaEH7"},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tn3clzzyaG6i"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='modelo_tokenizer',\n","    overwrite_output_dir=True,\n","    num_train_epochs=100,\n","    per_device_train_batch_size=64,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"p3k2JJC2aXMS","outputId":"b9031eeb-7c13-4bb4-c890-1e5e7531cc62","executionInfo":{"status":"ok","timestamp":1716748870317,"user_tz":180,"elapsed":27693072,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='15700' max='15700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15700/15700 7:41:30, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>5.077100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.567600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>4.399300</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>4.320600</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>4.313800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>4.149200</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>4.050900</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.928100</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>3.904800</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.813200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>3.727300</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>3.645500</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>3.601800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>3.524400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>3.481200</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>3.420900</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>3.333500</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>3.295700</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>3.200400</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>3.188500</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>3.140500</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>3.124300</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>3.067800</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>3.002100</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>3.022800</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>2.988000</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>2.944300</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>2.907900</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>2.925300</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>2.855400</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>2.903600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=15700, training_loss=3.5351110062325835, metrics={'train_runtime': 27692.8902, 'train_samples_per_second': 36.11, 'train_steps_per_second': 0.567, 'total_flos': 981285967902720.0, 'train_loss': 3.5351110062325835, 'epoch': 100.0})"]},"metadata":{},"execution_count":18}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7pKTQyWanFO"},"outputs":[],"source":["trainer.save_model('modelo_tokenizer')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4sZ5S7vavkk"},"outputs":[],"source":["from transformers import pipeline\n","\n","fill_mask = pipeline(\n","    \"fill-mask\",\n","    model='modelo_tokenizer',\n","    tokenizer='modelo_tokenizer'\n",")"]},{"cell_type":"code","source":["def retornaMask(lista):\n","    maior = 0\n","    resulta = ''\n","    for i in resultado:\n","        if i['score'] > maior:\n","            maior = i['score']\n","            resulta = i['token_str']\n","    return resulta"],"metadata":{"id":"Iq2FIGZ4aqXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultado = fill_mask('1 + <mask> = 10')\n","resultado_final = retornaMask(resultado)\n","\n","print(\"O numero a ser soma é o:\", resultado_final)"],"metadata":{"id":"qzOOt6FvehJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultado = fill_mask('55 + <mask> = 188')\n","resultado_final = retornaMask(resultado)\n","\n","print(\"O numero a ser soma é o:\", resultado_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOQSF98nfg3g","executionInfo":{"status":"ok","timestamp":1716753719259,"user_tz":180,"elapsed":286,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"ba86958c-20f2-4f2d-d758-017670e65917"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["O numero a ser soma é o:  54\n"]}]},{"cell_type":"code","source":["resultado = fill_mask('<mask> + 9 = 10')\n","resultado_final = retornaMask(resultado)\n","\n","print(\"O numero a ser soma é o:\", resultado_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mDn-vRCe1XO","executionInfo":{"status":"ok","timestamp":1716753507763,"user_tz":180,"elapsed":323,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"fffde299-4385-48bc-dc3b-301189edd974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["O numero a ser soma é o: 1\n"]}]},{"cell_type":"code","source":["resultado = fill_mask('<mask> + 90 = 100')\n","resultado_final = retornaMask(resultado)\n","\n","print(\"O numero a ser soma é o:\", resultado_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFwJCNIqfUzS","executionInfo":{"status":"ok","timestamp":1716753652400,"user_tz":180,"elapsed":258,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"83a1c653-b605-49f6-b197-5017e78ac487"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["O numero a ser soma é o: 11\n"]}]},{"cell_type":"code","source":["resultado = fill_mask('100 + 900 = <mask>')\n","resultado_final = retornaMask(resultado)\n","\n","print(\"O resultado da soma é:\", resultado_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uN1Q1_wGe5jf","executionInfo":{"status":"ok","timestamp":1716753589807,"user_tz":180,"elapsed":256,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"0ca3725f-c0d8-4468-e2ea-23eca10f13c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["O resultado da soma é:  797\n"]}]},{"cell_type":"code","source":["resultado = fill_mask('150 + 900 = <mask>')\n","resultado_final = retornaMask(resultado)\n","\n","print(\"O resultado da soma é:\", resultado_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-hSSu3NfPsm","executionInfo":{"status":"ok","timestamp":1716753601728,"user_tz":180,"elapsed":252,"user":{"displayName":"Leonardo Henrique leoHE","userId":"14224289085828235530"}},"outputId":"0068a400-d65b-425c-d195-1e349b1cc34d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["O resultado da soma é:  1135\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}